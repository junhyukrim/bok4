{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from ekonlpy.tag import Mecab\n",
    "import csv\n",
    "import os\n",
    "\n",
    "# CSV 파일이 있는 폴더 경로\n",
    "input_folder = \"C:/Users/hp/Downloads/total_bond_csv/bond_merged/final\"\n",
    "output_folder = \"C:/Users/hp/Downloads/total_bond_csv/bond_merged/final\"\n",
    "\n",
    "# output 폴더 없으면 생성\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Mecab 초기화\n",
    "mecab = Mecab()\n",
    "\n",
    "# 채택어 설정\n",
    "adopted_pos = [\n",
    "    'NNG', 'VA', 'VAX', 'MAG', 'VA', 'VCN', 'VX', 'NNP'\n",
    "]\n",
    "\n",
    "# 불용어 설정\n",
    "stop_words = [\n",
    "    ('리뷰', 'NNP')\n",
    "]\n",
    "\n",
    "# 품사 태깅 함수\n",
    "def pos_tagging(text):\n",
    "    if not isinstance(text, str) or text.strip() == \"\":\n",
    "        return []\n",
    "    return mecab.pos(text)\n",
    "\n",
    "# 토큰만 추출하는 함수\n",
    "def only_tokens(text):\n",
    "    if not isinstance(text, str) or text.strip() == \"\":\n",
    "        return []\n",
    "    return [word for word, pos in mecab.pos(text)]\n",
    "    \n",
    "# 클린 토큰 함수(불용어 제외)\n",
    "def clean_tokens(pos_tags):\n",
    "    return [\n",
    "        (word, pos) for (word, pos) in pos_tags\n",
    "        if (word, pos) not in stop_words and pos in adopted_pos\n",
    "    ]\n",
    "\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.endswith('.csv'):\n",
    "        file_path = os.path.join(input_folder, filename)\n",
    "        print(f'처리 중: {filename}')\n",
    "\n",
    "        # CSV 파일 읽기\n",
    "        df = pd.read_csv(file_path, encoding='utf-8-sig')\n",
    "\n",
    "        # # 열에 대해 적용\n",
    "        # df['tokenized'] = df['original_sentence'].apply(only_tokens)\n",
    "        df['pos_tagged'] = df['original_sentence'].apply(pos_tagging)\n",
    "        df['cleaned_tokens'] = df['pos_tagged'].apply(clean_tokens)\n",
    "\n",
    "        # 파일명 변경 후 저장\n",
    "        output_filename = filename.replace('.csv', '_clean_tokenized.csv')\n",
    "        output_path = os.path.join(output_folder, output_filename)\n",
    "        df.to_csv(\n",
    "            output_path,\n",
    "            index=False,\n",
    "            encoding='utf-8-sig',\n",
    "            quoting=csv.QUOTE_MINIMAL,  # 따옴표 자동 처리\n",
    "            sep=','\n",
    "        )\n",
    "        print(f'{output_filename} 저장 완료')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crawl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
