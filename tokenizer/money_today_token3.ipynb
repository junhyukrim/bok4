{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token_money_today_202502.csv 저장 완료.\n"
     ]
    }
   ],
   "source": [
    "from ekonlpy.tag import Mecab\n",
    "from konlpy.tag import Okt\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Mecab & Okt 객체 생성\n",
    "mecab = Mecab()\n",
    "okt = Okt()\n",
    "\n",
    "# 문장에서 한 글자 단어를 문맥에 맞게 변형하는 함수\n",
    "def adjust_single_char_tokens(sentence):\n",
    "    pos_result = mecab.pos(sentence)  # 품사 태깅\n",
    "    adjusted_sentence = []\n",
    "\n",
    "    for word, pos in pos_result:\n",
    "        # 한 글자 단어에 대해 문맥을 고려하여 변형\n",
    "        if len(word) == 1:\n",
    "            if pos.startswith('V'):  # 동사인 경우\n",
    "                adjusted_sentence.append(word + \"다\")  # \"있\" => \"있다\"\n",
    "            elif pos.startswith('A'):  # 형용사인 경우\n",
    "                adjusted_sentence.append(word + \"다\")  # \"좋\" => \"좋다\"\n",
    "            else:\n",
    "                adjusted_sentence.append(word)  # 그 외의 경우는 그대로\n",
    "        else:\n",
    "            adjusted_sentence.append(word)\n",
    "\n",
    "    return \" \".join(adjusted_sentence)\n",
    "\n",
    "# 어간 추출 후 원형 복원하는 함수\n",
    "def extract_clean_tokens_from_pos(pos_tagged):\n",
    "    clean_tokens = []\n",
    "    \n",
    "    for word, pos in pos_tagged:\n",
    "        if pos.startswith(('N', 'V', 'A', 'M')):  # 명사, 동사, 형용사, 부사만 선택\n",
    "            lemma = okt.morphs(word)  # 원형 복원 적용\n",
    "            clean_tokens.extend(lemma)\n",
    "    \n",
    "    # 한 글자 단어를 문맥에 맞게 변형\n",
    "    adjusted_keywords = [adjust_single_char_tokens(word) for word in clean_tokens]\n",
    "    \n",
    "    return adjusted_keywords\n",
    "\n",
    "# CSV 파일 읽기\n",
    "df = pd.read_csv(r\"C:/Users/wosle/OneDrive/Desktop/프로젝트 파일/뉴스 클랜징/머니투데이/머니투데이전처리T.csv\", encoding=\"utf-8-sig\")\n",
    "\n",
    "# 저장할 경로 설정\n",
    "output_base_folder = r\"C:/Users/wosle/OneDrive/Desktop/프로젝트 파일/뉴스 클랜징/머니투데이\"\n",
    "\n",
    "# 년도별로 데이터 분리하여 저장\n",
    "for year in df['date'].apply(lambda x: pd.to_datetime(x).year).unique():\n",
    "    year_df = df[df['date'].apply(lambda x: pd.to_datetime(x).year == year)]\n",
    "    \n",
    "    # 월별로 데이터 나누어 저장\n",
    "    for month in range(1, 13):\n",
    "        month_df = year_df[year_df['date'].apply(lambda x: pd.to_datetime(x).month == month)]\n",
    "        \n",
    "        if month_df.empty:\n",
    "            continue  # 데이터가 없으면 건너뜀\n",
    "        \n",
    "        # 폴더 생성\n",
    "        folder_name = f\"{year}-{str(month).zfill(2)}\"\n",
    "        output_folder = os.path.join(output_base_folder, folder_name)\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "        \n",
    "        # 품사 태깅 적용 (ekonlpy 사용)\n",
    "        month_df[\"pos_tagged\"] = month_df[\"orgn_sntc\"].apply(lambda x: mecab.pos(str(x)))\n",
    "        \n",
    "        # 클린 토큰만 추출 (명사, 동사, 형용사, 부사 포함)\n",
    "        month_df[\"clean_token\"] = month_df[\"pos_tagged\"].apply(extract_clean_tokens_from_pos)\n",
    "        \n",
    "        # 첫 번째 날짜와 마지막 날짜 추출 (파일명에 반영)\n",
    "        first_date = month_df['date'].min()\n",
    "        last_date = month_df['date'].max()\n",
    "        \n",
    "        # 새로운 파일명 생성\n",
    "        new_filename = f\"token_money_today_{first_date[:4]}{first_date[5:7]}.csv\"\n",
    "        output_path = os.path.join(output_folder, new_filename)\n",
    "        \n",
    "        # pos_tagged 열 제거 후 저장\n",
    "        month_df.drop(columns=['pos_tagged'], inplace=True)\n",
    "        \n",
    "        # 파일 저장\n",
    "        month_df.to_csv(output_path, index=False, encoding=\"utf-8-sig\", quoting=1)\n",
    "        print(f\"{new_filename} 저장 완료.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crawl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
