{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 첫 번째 CSV 파일 로드\n",
    "df1 = pd.read_csv('파이낸셜_진짜_최종.csv')\n",
    "\n",
    "# 두 번째 CSV 파일 로드\n",
    "df2 = pd.read_csv('naver_news_Financial_News_merged.csv')\n",
    "\n",
    "# 첫 번째 데이터프레임에서 content가 NaN인 id 값 찾기\n",
    "nan_ids = df1[df1['content'].isna()]['id'].astype(str)  # id를 문자열로 변환\n",
    "\n",
    "# 두 번째 데이터프레임에서 url에 해당 id 값이 포함된 행 찾기\n",
    "matching_urls = df2[df2['url'].apply(lambda x: any(str(id) in x for id in nan_ids))]\n",
    "\n",
    "# 'date' 열을 날짜 형식으로 변환\n",
    "df2['date'] = pd.to_datetime(df2['date'], errors='coerce')\n",
    "\n",
    "# 'date'가 2021-01-20 이후인 행 필터링\n",
    "filtered_urls = matching_urls[matching_urls['date'] > '2008-01-01']\n",
    "\n",
    "# 결과를 새로운 CSV 파일로 저장\n",
    "filtered_urls.to_csv('결측치 확인1.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crawl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
